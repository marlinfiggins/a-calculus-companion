\section{Fundamental Theorems of Calculus}

%% Include applications of FTC, physics? Basic Mechanics. position, velocity, acceleration, starting from velocity function.

%% Add useful examples for each of the techniques!!


%% u-sub Expectation of Exponential distribution? Frame in terms of chemical decay / half life? Expectation of normal distribution

%% LIATE for IBP

%% Derivation of Taylor's formula by IBP (https://math.stackexchange.com/questions/20397/striking-applications-of-integration-by-parts) maybe save for Taylor's theorem or as a hint for it

%% IBP: Gamma function and acting like factorial, provide history on it


%% Later chapter: intro to Fourier Series pair with Taylor's theorem


\subsection{Indefinite Integrals}


In general, we want to be able to compute the actual value of the integral in an easy way, not just establish a crude estimate or use Riemann sums to compute the value as it can be tedious or impossible. In order to make the process of finding integrals easier, we'll begin to establish a relationship between differentiation and integration. We'll start with the notion of an anti-derivative.
\begin{defn}[Anti-derivative]
If $f$ is a function on $[a,b]$, we say that a differentiable function $F$ is an \emph{anti-derivative} if $F'(x)=f(x)$ for all $x\in [a,b]$.
\end{defn}
\begin{prop}\label{PlusC}
  If $F$ is an anti-derivative of $f$, then $F(x)+C$ is also an anti-derivative of $f$ for any constant $C$. Moreover, if $F_1$ and $F_2$ are anti-derivatives, then they differ by a constant.
\end{prop}
\begin{proof}
  Since the derivative of any constant $C$ is $0$, the derivative of $F$ must equal the derivative of $F(x)+C$. Similarly, if $F_1$ and $F_2$ are two anti-derivatives of $f$, then $F_1-F_2$ must have derivative 0. Therefore, their difference is constant, so that $F_1(x)=F_2(x)+C$ for some $C$.
\end{proof}

\begin{defn}[Indefinite Integral]
With \cref{PlusC} in mind, we define the \emph{indefinite integral of $f$} as
\begin{equation}
  \int f(x)dx\coloneqq F(x)+C,
\end{equation} where $F$ is an anti-derivative of $f$. We use $C$ as placeholder constant to denote all positive anti-derivatives of f.
\end{defn}

Armed with this, we can now state one of the two Fundamental theorems of calculus.

\begin{thm}[The First Fundamental Theorem of Calculus]\label{FundThmOne}
  Suppose $f$ is a continuous function on the interval $[a,b]$. If we define \begin{equation}
    F(x)=\int_{a}^x f(t)dt,\text{ then } F'(x)=f(x),
  \end{equation}
  i.e. $\int_{a}^x f(t)dt$ is an anti-derivative of $f(x)$.
\end{thm}
Therefore, any continuous function of an interval has an anti-derivative on that interval.
\begin{thm}[The Second Fundamental Theorem of Calculus]\label{FundThmTwo} If $f$ is integrable on $[a,b]$, then \begin{equation}\label{FTC2}
  \int_{a}^{b}f(x)dx=F(b)-F(a)
\end{equation}for any anti-derivative $F$.
\end{thm}
\begin{rem}
  Notice that the Second Fundamental Theorem of Calculus is independent of our choice of anti-derivative by \cref{PlusC}, so we can always set $C=0$. That is, provided $F$ exists. We will often use $\eval{F(x)}_{a}^{b}$ as shorthand for $F(b)-F(a)$, emphasizing the relationship between the indefinite and definite integrals.
\end{rem}

\cref{FundThmOne} and \cref{FundThmTwo} are called the Fundamental Theorems of Calculus (FTC for short) because they establish the relationship between differentiation and integration. The idea being that the derivative and integration are functionally opposite operatives. One immediate result of the \cref{FundThmTwo} is that we have drastically simplified the problem of computing the definite integral; we simply need to find an anti-derivative.\\

The Fundamental Theorems of Calculus make the problem of finding the definite integral of functions like $f(x)=x$ much simpler as we can compute that
\begin{equation}
  \int_{a}^{b}x\ dx=\frac{b^2}{2}-\frac{a^2}{2}
\end{equation}
since $\frac{x^2}{2}$ is an anti-derivative of $x$. In fact, we can easily derive a more general statement for the indefinite integral of powers of $x$.

\begin{prop}[Reverse Power Rule]\label{RevPowRule}
  If $f(x)=x^n$ for some $n\neq -1$, then $f$ has anti-derivative $F(x)=\frac{x^{n+1}}{n+1}$ i.e
  \begin{equation}
    \int x^n\ dx=\frac{x^{n+1}}{n+1}+C.
  \end{equation}
\end{prop}

\begin{rem}
  In particular, this shows that for any constant $c=cx^0$, we have $\int c\ dx=cx$ which is consistent with \cref{ConstInt}.
\end{rem}

Using the linearity of the integral, we can use \cref{RevPowRule} to derive a formula for the indefinite integral (or anti-derivative) of any polynomial.
\begin{cor}\label{PolyInt}
If we have a polynomial $p(x)=a_nx^n+a_{n-1}x^{n-1}\dotsb+a_1x+a_0$ where the $a_i$ are constants, then
\begin{equation}
  \int p(x)dx= \left(\frac{a_n}{n+1}\right)x^{n+1}+ \left(\frac{a_{n-1}}{n}\right)x^{n}+\dotsb+\left(\frac{a_1}{2}\right)x^2+a_0x+C.
\end{equation}
\begin{proof}
  Writing our polynomial as $p(x)=\sum_{i=0}^{n}a_ix^i$ using sum notation, we can use \cref{SumIntCom} to see that
  \begin{equation}
    \int p(x)dx= \int \left(\sum_{i=0}^{n}a_ix^i\right)dx=\sum_{i=0}^{n}\left( \int a_ix^i dx \right).
  \end{equation}
  Therefore, we can use \cref{RevPowRule} to compute the integral on the righthand side, so that
  \begin{equation}
      \int p(x)dx=\sum_{i=0}^{n}\left( \frac{ a_i}{i+1}\right) x^{i+1}+C.
  \end{equation}
\end{proof}
\end{cor}

\subsection{Consequences of the Fundamental Theorems}

%% Need more expositon. Examples after each theorem.

We can derive similar formulas for the integrals of the trigonometric functions with
\begin{equation}
  \int\sin(x)\ dx= -\cos(x)+C
 \text{ and }   \int_{a}^{b}\cos(x)\ dx=\sin(x)+C,
\end{equation}
which for now we will take as granted.

%% This follows from the theorem I proved earlier... \href{SinCosExpDif} so it's not for granted. Pls fix.

%% We have this example, but what if we're dealing with a function like \sin x \cos x

%% has anti-derivatives \sin^2 and  -\cos^2x

We can also define formulas for the integrals composition of functions.

\begin{thm}[$u$-Substitution]\label{USub}
  For functions $f,u$ such that $u$ is differentiable on $[a,b]$ and $f$ is continuous on the image $u([a,b])$,
  \begin{equation}
    \int_{a}^{b}f(u(x))u'(x)dx=\int_{u(a)}^{u(b)}f(x)dx.
  \end{equation}
\end{thm}

\begin{proof}
  Since $f$ is continuous, it has an anti derivative $F$. Noticing that $F\circ u$ has derivative $F'(u(x))u'(x)$ by chain rule, we see that $F\circ u$ is an anti derivative of $f(u(x))u'(x)$. Therefore, \cref{FundThmTwo} tells us that
  \begin{equation}
      \int_{a}^{b}f(u(x))u'(x)dx=F(u(b))-F(u(a))=\int_{u(a)}^{u(b)}f(x)dx.
  \end{equation}
\end{proof}
\begin{rem}
  There is an direct analogue of this for indefinite integrals which we will use later.
\end{rem}

Notice this resembles the chain rule, but in reverse. This allows us to reduce integrals of many functions into the cases we've described above. Similarly, we can prove a sort of reverse product rule.

%% Completing the example above


%% What if we can write the problem in terms of a derivative and a function... product of two (incapatible) functions. For example, $x^2 e^x$

\begin{thm}[Integration by Parts]\label{IBP}
For differentiable functions $u,v$ on $[a,b]$,
\begin{equation}
  \int_{a}^{b}u\ dv=\eval{(uv)}^{b}_{a}-\int_{a}^{b}v\ du.
\end{equation}
where $dv$ and $du$ denote $v'(x)dx$ and $u'(x)dx$ respectively.
\end{thm}
\begin{proof}
  Consider the function $u\cdot v$. By the product rule, its derivative is $uv'+vu'$. Therefore, linearity of the integral and FTC tell us
  \begin{equation}
  \eval{(uv)}^{b}_{a}= \int_{a}^{b}[u(x)v'(x)+v(x)u'(x)]dx=\int_{a}^{b}u(x)v'(x)dx + \int_{a}^{b}v(x)u'(x)dx.
\end{equation}
Making the substitutions $dv=v'(x)dx$, $du=u'(x)dx$ and subtracting over the second term, we get the result
\begin{equation*}
  \int_{a}^{b}u\ dv=\eval{(uv)}^{b}_{a}-\int_{a}^{b}v\ du.
\end{equation*}
\end{proof}

%% Write function to draw integrals for the symmetric case.
Furthermore, we can see that integral is consistent with our geometric intuition of area under the curve when it comes to functions with symmetry.
\begin{prop}[Integrating Even and Odd Functions]\label{SymInt}
  Suppose $f$ is continuous on $[-b, b]$, then
  \begin{align}
    \int_{-b}^{b}f(x)dx&=2\int_{0}^{b}f(x)dx \text{ if  $f$ is even, and}\\
    \int_{-b}^{b}f(x)dx&=0  \text{ if  $f$ is odd}.
  \end{align}
\end{prop}

\begin{prop}[Integrating Periodic Functions]\label{PerInt}
  If $f$ is continuous and periodic with period $T$, then \begin{equation}
      \int_{x}^{x+T}f(x)dx=\int_{0}^{T}f(x)dx \text{ for any $x$.}
  \end{equation}
\end{prop}

We can use these to compute the followings examples. %% Do several practice integrals.
\begin{exmps}

Compute the indefinite integral $\int f(x)dx$ for the following functions:
\begin{enumerate}[label=\textbf{Example A.\arabic*.}]
  \addtolength{\itemindent}{1.625cm} % move right
  \item \label{IntEA1} $f(x)=x^5+2x+1$, %% Hint: \cref{PolyInt}
  \item \label{IntEA2} $f(x)=\cos(x)\sin^2(x)$, %% Hint:\cref{USub}
  \item \label{IntEA3} $f(x)= \sin^2(x)+\cos^2(x)$, %% Trig
  \item \label{IntEA4} $f(x)=\frac{3x}{\sqrt{x^2+1}}$, %%\cref{USub}+\\ref{RevPowRule}
  \item \label{IntEA5} $f(x)= 3x\cos(x)$ %%\cref{IBP}
\end{enumerate}

Starting with \ref{IntEA1}, we can see that this is an application of \cref{PolyInt}, so that
\[
\int (x^5+2x+1)\ dx=\frac{x^6}{6}+x^2+x+C.
\]

For \ref{IntEA2}, we'll need $u$-substitution. Noticing that the derivative of $\sin^2(x)$ will have a $\cos(x)$ in front by Chain Rule ($\diff{}{x}(\sin x)=\cos x$), we define $u=\sin(x)$ so that $du=\cos(x)dx$. Therefore, we can make these substitutions and see
\[
\int \cos(x)\sin^2(x)dx=\int \underbrace{\sin^2(x)}_{u^2}\underbrace{\cos(x)dx}_{du}=\int u^2du= \frac{1}{3}u^3+C.
\]
To finish, we have to back substitute, so that everything is in terms of $x$, so our final answer is
\[
\int \cos(x)\sin^2(x)dx=\frac{1}{3}\sin^3(x)+C.
\]
\ref{IntEA3} comes down to the trig identity $\sin^2(x)+\cos^2(x)=1$, so that
\[
\int \sin^2(x)+\cos^2(x) dx= \int 1\ dx= x+C.
\]

Moving onto \ref{IntEA4}, we see that the function $x^2+1$ has derivative $2x$, so we can try $u$-substitution again. Making the substitution $u=x^2+1$, we get $du=2x$, so that $\frac{3}{2}du=3x\ dx$. Therefore, making these substitutions, we compute
\begin{align}
  \int \frac{3x}{\sqrt{x^2+1}}\ dx=\frac{3}{2}\int\frac{1}{\sqrt{u}}du& =\frac{3}{2}\int u^{-\frac{1}{2}}du\\
  &= \frac{3}{2}\cdot2u^{\frac{1}{2}}+C, \text{ by \cref{RevPowRule}}\\
  &= 3(x^2+1)^{\frac{1}{2}}+C, \text{ back substituting }u=x^2+1.
\end{align}

We can see that \ref{IntEA5} is the product of two functions, neither of which contains the derivative of the other, so $u$-substitution will not work. Therefore, we try the product rule. Letting, $u=3x$ and $dv'=\cos(x)$, we have $u'=3$ and $v=\sin(x)$. Plugging this into the formula, we get
\[
\int 3x\cos(x)dx= 3x\sin(x)-\int 3\sin(x)dx=3x\sin(x)-3\cos(x)+C.
\]
\\

Let's try to do the same for definite integrals.

Compute the definite integral $\int_{a}^{b} f(x)$ for the following functions:
\begin{enumerate}[label=\textbf{Example B.\arabic*.}]
  \addtolength{\itemindent}{1.625cm} % move right
  \item \label{IntEB1} $f(x)=x^3, a=-2, b=4$
  \item \label{IntEB2} $f(x)=\sin^{5001}(x), a=-1, b=1$, %% Hint: Odd
  \item \label{IntEB3} $f(x)=4x(x^2+8)^3$,               %% Hint: u-sub
  \item \label{IntEB4} $f(x)=\sin(x)\cos^2(x), a=-\frac{3\pi}{2},b=\frac{5\pi}{2}$ %% Hint: u-sub/odd
  \item \label{IntEB5} $f(x)=\abs{\cos(x)}, a=0, b=2000\pi$ %% Hint: Even
\end{enumerate}

Starting with \ref{IntEB1}, we can see this is just an application of the reverse power rule, so that
\[
\int_{-2}^{4}x^3=\eval{\left(\frac{x^4}{4}\right)}^{4}_{-2}=\frac{4^4}{4}-\frac{(-2)^4}{4}=64-4=60.
\]

\ref{IntEB2} looks to be ridiculously hard to solve directly. We'll need to be clever here. Noticing that $\sin x$ is odd and that, therefore, $\sin^{5001}(x)$ must be odd, we can use this symmetry as in \cref{SymInt} to see that $\int_{-1}^{1} \sin^{5001}(x)dx=0$.\\


\ref{IntEB3} and \ref{IntEB4} are applications of $u$-substitution and will be left as exercises.

Lastly, \ref{IntEB5} can be solved using the periodic of $\abs{\cos (x)}$. Since $\abs{\cos (x)}$ has period $\pi$, we can decompose the integral as
\[
\int_{0}^{2000\pi}\abs{\cos(x)}dx=2000\int_{0}^{\pi}\abs{\cos(x)}dx
\]
using \cref{PerInt}. This leaves us to calculate $\abs{\cos(x)}$. Since $\cos(x)$ is non-negative on $[0,\frac{\pi}{2}]$ and negative on $[\frac{\pi}{2}, \pi]$, we can once again decompose the integral to find
\[
\int_{0}^{\pi}\abs{\cos(x)}dx= \int_{0}^{\frac{\pi}{2}}\cos(x)dx-\int_{\frac{\pi}{2}}^{\pi}\cos(x)dx=\eval{\sin(x)}_{0}^{\frac{\pi}{2}}-\eval{\sin(x)}_{\frac{\pi}{2}}^{\pi}=2\sin\left(\frac{\pi}{2}\right)=2.
\]
Therefore, our final answer is
\[
\int_{0}^{2000\pi}\abs{\cos(x)}dx=4000.
\]
\end{exmps}


With our knowledge that differentiation and integration are a kind of reciprocal operations via the FTC, we can prove an analogue of the Mean Value theorem for integrals.
\begin{thm}[Mean Value Theorem for Integrals]
  If $f$ is continuous on $[a,b]$, then there exists some point $c$ in $[a,b]$ such that
  \begin{equation}
    f(c)=\frac{1}{b-a}\int_{a}^{b}f(x)dx.
  \end{equation}
\end{thm}
\begin{proof}
  Since $f$ is continuous, we have an anti-derivative $F(x)=\int_{a}^{x}f(t)dt$ which is differentiable on $(a,b)$ and continuous on $[a,b]$. Therefore, the Mean Value theorem for derivatives (\cref{MVTD}) states there is some $c$ such that
  \begin{equation}
    F'(c)=\frac{1}{b-a}\big(F(b)-F(a) \big).
  \end{equation}
  Since $F$ is an anti-derivative of $f$ and $\int_{a}^{a}f(t)dt=0$, we have
\begin{equation}
  f(c)=F'(c)=\frac{1}{b-a}\left( \int_{a}^{b}f(t)dt-\int_{a}^{a}f(t)dt \right)=\frac{1}{b-a}\int_{a}^{b}f(x)dx.
\end{equation}
\end{proof}
\begin{rem}
  The Mean Value Theorem for integrals gives a way of finding the average value of a function over an interval. The integral of $f$ amounts to summing up all the values $f$ on the interval $[a,b]$, then the factor of $\frac{1}{b-a}$ accounts for length of the interval that we summed over.
\end{rem}

Now that we've a solid grounding in how integration works and some of its important tools, we'll move to the kinds of problems in which integration can be applied.
